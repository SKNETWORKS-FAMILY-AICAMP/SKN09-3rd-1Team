{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 판례 수: 9654\n",
      "판례내용이 비어있는 항목 수: 4105\n",
      "판례내용 항목 수: 5549\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 1. JSON 파일 열기\n",
    "with open(\"./data/filtered_case_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 2. 판례내용이 비어있는 항목과 비어있지 않은 항목 나누기\n",
    "non_empty_case_contents = [case for case in data if case.get(\"판례내용\")]\n",
    "\n",
    "# 3. 새 파일로 저장\n",
    "with open(\"./data/filtered_case_data_non_empty.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(non_empty_case_contents, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 4. 확인 출력\n",
    "print(f\"전체 판례 수: {len(data)}\")\n",
    "print(f\"판례내용이 비어있지 않은 항목 수: {len(non_empty_case_contents)}\")\n",
    "print(\"✅ filtered_case_data_non_empty.json 파일 저장 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 조문 항별 분할 완료! cleaned_law_data_preprocessed.json 에 저장됨.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# 항목 분리 함수 정의\n",
    "def split_articles(text):\n",
    "    matches = list(re.finditer(r'(①|②|③|④|⑤|⑥|⑦|⑧|⑨|⑩)', text))\n",
    "    if not matches:\n",
    "        return {\"제1항\": text.strip()}\n",
    "\n",
    "    result = {}\n",
    "    for i in range(len(matches)):\n",
    "        start = matches[i].start()\n",
    "        end = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "        content = text[start + 1:end].strip()\n",
    "        result[f\"제{i + 1}항\"] = content\n",
    "    return result\n",
    "\n",
    "# 파일 열기\n",
    "with open(\"./data/cleaned_law_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "processed_data = {}\n",
    "\n",
    "# 법률명 단위로 반복\n",
    "for law_name, articles in raw_data.items():\n",
    "    processed_articles = []\n",
    "    for article in articles:\n",
    "        content = article.get(\"조항내용\", \"\")\n",
    "        article[\"조항내용\"] = split_articles(content)\n",
    "        processed_articles.append(article)\n",
    "    processed_data[law_name] = processed_articles\n",
    "\n",
    "# 저장\n",
    "with open(\"./data/cleaned_law_data_preprocessed.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(processed_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"✅ 조문 항별 분할 완료! cleaned_law_data_preprocessed.json 에 저장됨.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (0.2.17)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.2.19-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: chromadb in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (0.5.23)\n",
      "Requirement already satisfied: gradio in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (4.44.1)\n",
      "Requirement already satisfied: tiktoken in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from langchain) (3.10.11)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.43 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from langchain) (0.2.43)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from langchain) (8.5.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from langchain-openai) (1.68.2)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (0.115.11)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.33.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (3.21.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (1.19.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (0.20.3)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (6.4.5)\n",
      "Requirement already satisfied: graphlib_backport>=1.0.3 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (1.70.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (4.5.2)\n",
      "Requirement already satisfied: ffmpy in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (0.29.3)\n",
      "Requirement already satisfied: jinja2<4.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (3.7.5)\n",
      "Requirement already satisfied: packaging in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (2.0.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydub in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (0.11.2)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: fsspec in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio-client==1.3.0->gradio) (2025.3.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.15.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from build>=1.0.3->chromadb) (8.5.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from fastapi>=0.95.2->chromadb) (0.44.0)\n",
      "Requirement already satisfied: certifi in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from huggingface-hub>=0.19.3->gradio) (3.16.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from importlib-resources->chromadb) (3.20.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from langchain-core<0.3.0,>=0.2.43->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from matplotlib~=3.0->gradio) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from matplotlib~=3.0->gradio) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
      "Requirement already satisfied: coloredlogs in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
      "Requirement already satisfied: sympy in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.31.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.52b1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.52b1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from pydantic<3,>=1->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.43->langchain) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Downloading langchain_community-0.2.19-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.1.25-py3-none-any.whl (51 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-openai, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.19 langchain-openai-0.1.25 marshmallow-3.22.0 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community langchain-openai chromadb gradio tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0.post1-cp38-cp38-macosx_10_14_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from faiss-cpu) (1.24.4)\n",
      "Requirement already satisfied: packaging in /Users/sky/Documents/skn/skn-3rd-1Team/skn3/lib/python3.8/site-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.8.0.post1-cp38-cp38-macosx_10_14_x86_64.whl (7.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 벡터 DB가 없어 생성합니다...\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/bf749bkd2lv_11d1rlyjcgz00000gn/T/ipykernel_34480/906641993.py:78: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  result = qa_chain(query)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import gradio as gr\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Set API key\n",
    "\n",
    "# Load and split law data\n",
    "def load_and_split_law_data(path=\"data/cleaned_law_data_preprocessed.json\"):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    docs = []\n",
    "    for law_name, articles in data.items():\n",
    "        for article in articles:\n",
    "            조문번호 = article[\"조항번호\"]\n",
    "            제목 = article[\"조항제목\"]\n",
    "            조문내용 = article[\"조항내용\"]\n",
    "            for 항, 내용 in 조문내용.items():\n",
    "                full_text = f\"[{law_name} {조문번호} {항}] {제목}\\n{내용}\"\n",
    "                docs.append(Document(page_content=full_text, metadata={\n",
    "                    \"source\": f\"{law_name} {조문번호} {항}\"\n",
    "                }))\n",
    "    return docs\n",
    "\n",
    "# Load and split case data\n",
    "def load_and_split_case_data(path=\"data/filtered_case_data.json\"):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    docs = []\n",
    "    for case in data:\n",
    "        if case.get(\"판례내용\"):\n",
    "            content = json.dumps(case[\"판례내용\"], ensure_ascii=False, indent=2)\n",
    "            title = case[\"사건명\"]\n",
    "            metadata = {\n",
    "                \"사건번호\": case[\"사건번호\"],\n",
    "                \"선고일자\": case[\"선고일자\"],\n",
    "                \"사건명\": case[\"사건명\"]\n",
    "            }\n",
    "            docs.append(Document(page_content=f\"[판례] {title}\\n{content}\", metadata=metadata))\n",
    "    return docs\n",
    "\n",
    "# Build vector DB (only once)\n",
    "def build_vectorstore():\n",
    "    law_docs = load_and_split_law_data()\n",
    "    case_docs = load_and_split_case_data()\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)\n",
    "    all_docs = splitter.split_documents(law_docs + case_docs)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectordb = FAISS.from_documents(all_docs, embedding=embeddings)\n",
    "    vectordb.save_local(\"law_case_db\")\n",
    "    return vectordb\n",
    "\n",
    "# Check if FAISS DB exists\n",
    "def initialize_vector_db():\n",
    "    if not os.path.exists(\"law_case_db/index.faiss\"):\n",
    "        print(\"📦 벡터 DB가 없어 생성합니다...\")\n",
    "        return build_vectorstore()\n",
    "    print(\"✅ 벡터 DB 로딩 중...\")\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    return FAISS.load_local(\"law_case_db\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Initialize vector DB\n",
    "vectordb = initialize_vector_db()\n",
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4o-mini\"),\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Gradio UI\n",
    "def answer_query(query):\n",
    "    result = qa_chain(query)\n",
    "    sources = \"\\n\\n\".join([\n",
    "        f\"🔹 {doc.metadata.get('source', '미상')}\\n{doc.page_content[:300]}...\"\n",
    "        for doc in result[\"source_documents\"]\n",
    "    ])\n",
    "    return result[\"result\"], sources\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=answer_query,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"예: 혼인무효 확인소송은 이혼 후에도 제기 가능한가요?\"),\n",
    "    outputs=[\"text\", \"text\"],\n",
    "    title=\"📚 법률+판례 RAG 검색기\",\n",
    "    description=\"자연어로 질문하면 관련 법조문과 판례를 검색하여 설명해줍니다.\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS 벡터 DB 로딩 중...\n",
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# ✅ LangSmith & OpenAI 환경 변수 설정\n",
    "\n",
    "# ✅ FAISS 벡터 DB 로딩 함수\n",
    "def initialize_vector_db():\n",
    "    if not os.path.exists(\"law_case_db/index.faiss\"):\n",
    "        raise FileNotFoundError(\"❌ FAISS DB 파일이 존재하지 않습니다. 먼저 build_vectorstore()를 실행해주세요.\")\n",
    "    print(\"✅ FAISS 벡터 DB 로딩 중...\")\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    return FAISS.load_local(\"law_case_db\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# ✅ 프롬프트 템플릿 정의 (가족법 전문 AI 상담사 역할)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"context\"],\n",
    "    template=\"\"\"\n",
    "당신은 '가족법 전문 AI 상담사'입니다. 아래 사용자의 질문에 대해 제공된 문서 내용(법률 조문 및 판례)에 근거하여 정확하고 신중하게 답변해 주세요.\n",
    "\n",
    "❓질문:\n",
    "{question}\n",
    "\n",
    "📄참고 문서:\n",
    "{context}\n",
    "\n",
    "💬답변:\n",
    "- 위 문서의 내용에 기반하여 법적 해석 또는 설명을 제공하세요.\n",
    "- 명확한 표현을 사용하고, 문서에 없는 내용은 추측하지 마세요.\n",
    "- 법률 용어는 필요한 경우 간단히 풀이해 주세요.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# ✅ DB 및 체인 초기화\n",
    "vectordb = initialize_vector_db()\n",
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4o-mini\"),\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# ✅ 사용자 질문 응답 함수\n",
    "def answer_query(query):\n",
    "    query = query.strip()\n",
    "    if not query:\n",
    "        return \"❗질문을 입력해주세요.\", \"\"\n",
    "\n",
    "    result = qa_chain(query)\n",
    "    sources = \"\\n\\n\".join([\n",
    "        f\"🔹 {doc.metadata.get('source', '미상')}\\n{doc.page_content[:300]}...\"\n",
    "        for doc in result.get(\"source_documents\", [])\n",
    "    ])\n",
    "    return result.get(\"result\", \"답변 생성 중 오류가 발생했습니다.\"), sources\n",
    "\n",
    "# ✅ Gradio UI 구성\n",
    "demo = gr.Interface(\n",
    "    fn=answer_query,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"예: 협의이혼으로 위자료를 받았으면 사해행위가 될 수 없나요?\"),\n",
    "    outputs=[\"text\", \"text\"],\n",
    "    title=\"📚 가족법 해결사 - 이혼 & 양육권 상담 AI (LangSmith 추적 포함)\",\n",
    "    description=\"자연어로 질문하면 관련 법조문과 판례를 검색하여 설명해줍니다.\"\n",
    ")\n",
    "\n",
    "# ✅ 앱 실행\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파인 튜닝 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📚 Generating fine-tune data: 100%|██████████| 100/100 [06:14<00:00,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 파인튜닝용 데이터셋 저장 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# ✅ Step 0: API Key 설정\n",
    "\n",
    "# ✅ Step 1: 벡터 DB 로딩\n",
    "vectordb = FAISS.load_local(\"law_case_db\", OpenAIEmbeddings(), allow_dangerous_deserialization=True)\n",
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "# ✅ Step 2: RAG 기반 QA 체인 정의\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4o-mini\"),\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# ✅ Step 3: 질문 생성 프롬프트 + 체인 정의\n",
    "question_gen_prompt = PromptTemplate.from_template(\"\"\"\n",
    "다음 문서 내용을 바탕으로 법률 또는 판례와 관련된 자연스러운 질문 3가지를 생성해 주세요.\n",
    "\n",
    "문서:\n",
    "{context}\n",
    "\n",
    "질문:\n",
    "1.\n",
    "2.\n",
    "3.\n",
    "\"\"\")\n",
    "\n",
    "question_gen_chain = LLMChain(\n",
    "    llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7),\n",
    "    prompt=question_gen_prompt\n",
    ")\n",
    "\n",
    "# ✅ Step 4: 문서 로딩 함수\n",
    "def load_documents():\n",
    "    with open(\"data/filtered_case_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        cases = json.load(f)\n",
    "    with open(\"data/cleaned_law_data_preprocessed.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        laws = json.load(f)\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    # 법률 조문 문서\n",
    "    for law_name, articles in laws.items():\n",
    "        for article in articles:\n",
    "            title = article[\"조항제목\"]\n",
    "            num = article[\"조항번호\"]\n",
    "            content = article[\"조항내용\"]\n",
    "            for 항, 항내용 in content.items():\n",
    "                text = f\"[{law_name} {num} {항}] {title}\\n{항내용}\"\n",
    "                documents.append(Document(page_content=text))\n",
    "\n",
    "    # 판례 문서\n",
    "    for case in cases:\n",
    "        if case.get(\"판례내용\"):\n",
    "            text = json.dumps(case[\"판례내용\"], ensure_ascii=False, indent=2)\n",
    "            documents.append(Document(page_content=f\"[판례] {case['사건명']}\\n{text}\"))\n",
    "\n",
    "    return RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50).split_documents(documents)\n",
    "\n",
    "# ✅ Step 5: 파인튜닝 데이터 자동 생성\n",
    "def generate_finetune_data(docs, max_samples=100):\n",
    "    dataset = []\n",
    "    pbar = tqdm(total=max_samples, desc=\"📚 Generating fine-tune data\")\n",
    "\n",
    "    for doc in docs:\n",
    "        if len(dataset) >= max_samples:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            q_result = question_gen_chain.invoke({\"context\": doc.page_content})\n",
    "            questions_raw = q_result.get(\"text\", \"\")\n",
    "\n",
    "            questions = [\n",
    "                q.strip(\"-•1234567890. )\") for q in questions_raw.split(\"\\n\")\n",
    "                if len(q.strip()) > 10\n",
    "            ][:3]\n",
    "\n",
    "            for question in questions:\n",
    "                rag_result = qa_chain.invoke(question)\n",
    "\n",
    "                # context 추출\n",
    "                source_docs = rag_result.get(\"source_documents\", [])\n",
    "                context_texts = [\n",
    "                    doc.page_content for doc in source_docs\n",
    "                    if hasattr(doc, \"page_content\")\n",
    "                ]\n",
    "                context = \"\\n\\n\".join(context_texts)\n",
    "\n",
    "                dataset.append({\n",
    "                    \"instruction\": question,\n",
    "                    \"input\": context.strip(),\n",
    "                    \"output\": rag_result[\"result\"].strip()\n",
    "                })\n",
    "\n",
    "                pbar.update(1)\n",
    "                if len(dataset) >= max_samples:\n",
    "                    break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"⚠️ 오류 발생:\", e)\n",
    "            continue\n",
    "\n",
    "    pbar.close()\n",
    "    return dataset\n",
    "\n",
    "# ✅ Step 6: 실행 및 저장\n",
    "all_docs = load_documents()\n",
    "finetune_data = generate_finetune_data(all_docs, max_samples=100)\n",
    "\n",
    "os.makedirs(\"finetune_dataset\", exist_ok=True)\n",
    "with open(\"finetune_dataset/familylaw_finetune_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(finetune_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ 파인튜닝용 데이터셋 저장 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 유의미한 데이터만 165건으로 정제 완료!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 원본 파일 경로\n",
    "input_path = \"finetune_dataset/familylaw_finetune_data.json\"\n",
    "output_path = \"finetune_dataset/cleaned_familylaw_finetune_data.json\"\n",
    "\n",
    "# 제거하고 싶은 출력 텍스트 패턴들\n",
    "remove_phrases = [\n",
    "    \"죄송하지만\", \n",
    "    \"제공된 정보에 포함되어 있지 않습니다\", \n",
    "    \"답변을 드릴 수 없습니다\", \n",
    "    \"구체적인 정보는 알지 못합니다\", \n",
    "    \"정보가 없습니다\",\n",
    "    \"제가 알고 있는 정보가 없습니다\"\n",
    "]\n",
    "\n",
    "# 불필요한 응답인지 판단\n",
    "def is_useless_output(output: str) -> bool:\n",
    "    return any(phrase in output for phrase in remove_phrases)\n",
    "\n",
    "# 파일 불러오기\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 필터링\n",
    "filtered_data = [\n",
    "    item for item in data\n",
    "    if not is_useless_output(item[\"output\"])\n",
    "]\n",
    "\n",
    "# 저장\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(filtered_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ 유의미한 데이터만 {len(filtered_data)}건으로 정제 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📌 추가 100건 생성 중: 100%|██████████| 100/100 [06:05<00:00,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 누적 저장 완료! 총 200건.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ✅ 기존 데이터 로드\n",
    "existing_data_path = \"finetune_dataset/familylaw_finetune_data.json\"\n",
    "with open(existing_data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    existing_data = json.load(f)\n",
    "    existing_questions = set(item[\"instruction\"].strip() for item in existing_data)\n",
    "\n",
    "# ✅ 새 데이터 생성\n",
    "new_data = []\n",
    "pbar = tqdm(total=100, desc=\"📌 추가 100건 생성 중\")\n",
    "\n",
    "for doc in all_docs:\n",
    "    if len(new_data) >= 100:\n",
    "        break\n",
    "    try:\n",
    "        q_result = question_gen_chain.invoke({\"context\": doc.page_content})\n",
    "        questions_raw = q_result.get(\"text\", \"\")\n",
    "        questions = [\n",
    "            q.strip(\"-•1234567890. )\") for q in questions_raw.split(\"\\n\")\n",
    "            if len(q.strip()) > 10\n",
    "        ][:3]\n",
    "\n",
    "        for question in questions:\n",
    "            if question.strip() in existing_questions:\n",
    "                continue\n",
    "\n",
    "            rag_result = qa_chain.invoke(question)\n",
    "            source_docs = rag_result.get(\"source_documents\", [])\n",
    "            context_texts = [\n",
    "                doc.page_content for doc in source_docs\n",
    "                if hasattr(doc, \"page_content\")\n",
    "            ]\n",
    "            context = \"\\n\\n\".join(context_texts)\n",
    "\n",
    "            new_data.append({\n",
    "                \"instruction\": question,\n",
    "                \"input\": context.strip(),\n",
    "                \"output\": rag_result[\"result\"].strip()\n",
    "            })\n",
    "\n",
    "            existing_questions.add(question.strip())\n",
    "            pbar.update(1)\n",
    "            if len(new_data) >= 100:\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ 오류 발생:\", e)\n",
    "        continue\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# ✅ 기존 데이터 + 새 데이터 저장\n",
    "combined_data = existing_data + new_data\n",
    "with open(existing_data_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(combined_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ 누적 저장 완료! 총 {len(combined_data)}건.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파인튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# ✅ 1. 데이터 로드\n",
    "with open(\"cleaned_familylaw_finetune_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "# ✅ 2. Dataset 변환\n",
    "dataset = Dataset.from_list(raw_data)\n",
    "\n",
    "# ✅ 3. Tokenizer 로드 (예: Mistral or LLaMA3 or other open model)\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # 필요한 경우\n",
    "\n",
    "# ✅ 4. Prompt 포맷 (instruction + input + output 연결)\n",
    "def format_example(example):\n",
    "    prompt = f\"### 질문:\\n{example['instruction']}\\n\\n### 문서:\\n{example['input']}\\n\\n### 답변:\"\n",
    "    return {\n",
    "        \"input_ids\": tokenizer(prompt, truncation=True, padding=\"max_length\", max_length=1024)[\"input_ids\"],\n",
    "        \"labels\": tokenizer(example[\"output\"], truncation=True, padding=\"max_length\", max_length=256)[\"input_ids\"]\n",
    "    }\n",
    "\n",
    "tokenized_dataset = dataset.map(format_example)\n",
    "\n",
    "# ✅ 5. 모델 로드 및 QLoRA 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "# ✅ 6. LoRA 설정\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "# ✅ 7. 학습 인자\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qlora_familylaw\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# ✅ 8. Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# ✅ 9. 파인튜닝 시작\n",
    "trainer.train()\n",
    "\n",
    "# ✅ 10. 모델 저장\n",
    "model.save_pretrained(\"./qlora_familylaw/peft_model\")\n",
    "tokenizer.save_pretrained(\"./qlora_familylaw/peft_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM,\n",
    "    TrainingArguments, Trainer, BitsAndBytesConfig\n",
    ")\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
    "from huggingface_hub import login\n",
    "\n",
    "# ✅ Hugging Face 로그인 (토큰 입력)\n",
    "login(\"\")\n",
    "\n",
    "# ✅ CUDA 환경 설정 (GPU 1개만 사용)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# ✅ 데이터 로드\n",
    "with open(\"./data/cleaned_familylaw_finetune_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = json.load(f)\n",
    "dataset = Dataset.from_list(raw_data)\n",
    "\n",
    "# ✅ 모델/토크나이저 로드\n",
    "model_id = \"openchat/openchat-3.5-0106\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# ✅ 전처리 함수 정의\n",
    "def format_prompt(example):\n",
    "    prompt = f\"### 질문:\\n{example['instruction']}\\n\\n### 문서:\\n{example['input']}\\n\\n### 답변:\"\n",
    "    response = example[\"output\"]\n",
    "    full_text = prompt + \" \" + response\n",
    "\n",
    "    # 전체 시퀀스를 하나로 처리\n",
    "    tokenized = tokenizer(\n",
    "        full_text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=1024,\n",
    "    )\n",
    "\n",
    "    input_ids = tokenized[\"input_ids\"]\n",
    "    attention_mask = tokenized[\"attention_mask\"]\n",
    "\n",
    "    # 레이블은 input_ids 복사해서 답변 전까지는 마스킹\n",
    "    labels = input_ids.copy()\n",
    "\n",
    "    # prompt 길이만큼 -100 마스킹\n",
    "    prompt_len = len(tokenizer(prompt, truncation=True, max_length=1024)[\"input_ids\"])\n",
    "    labels[:prompt_len] = [-100] * prompt_len\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "\n",
    "tokenized_dataset = dataset.map(format_prompt)\n",
    "\n",
    "# ✅ QLoRA 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# ✅ 모델 로드 (GPU 0만 사용)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0},\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "# ✅ LoRA 설정\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "# ✅ 학습 인자\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qlora_openchat_familylaw\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# ✅ Trainer 정의 및 학습\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# ✅ 모델 저장\n",
    "model.save_pretrained(\"./qlora_openchat_familylaw/peft_model\")\n",
    "tokenizer.save_pretrained(\"./qlora_openchat_familylaw/peft_model\")\n",
    "\n",
    "# ✅ 파인튜닝 모델 테스트용 추론 함수\n",
    "def infer(instruction, context=\"\"):\n",
    "    model.eval()\n",
    "    prompt = f\"### 질문:\\n{instruction}\\n\\n### 문서:\\n{context}\\n\\n### 답변:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# ✅ 예시 추론\n",
    "print(infer(\"친권과 양육권의 차이점은 무엇인가요?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
